<html>
<head>
    <title> tsahay </title>
    <meta charset="utf-8"/>
<link href='//fonts.googleapis.com/css?family=Allan' rel='stylesheet'>
<link href='//fonts.googleapis.com/css?family=Sofia' rel='stylesheet'>
    <link rel="stylesheet" type="text/css" href="./mycss.css?version=1"></link>
 
<style>
ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
    overflow: hidden;
    background-color: #333;
}

li {
    float: left;
}

li a {
    display: block;
    color: white;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
}

li a:hover:not(.active) {
    background-color: #111;
}

.active {
    background-color: #00CED1;
}

    </style>
</head>

<body style="background: rgba(255, 255, 255, 0.85)">
<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="research.html">Research</a></li>
  <li><a class="active" href="publication.html">Publications</a></li>
  <li><a href="blog.html">Blog</a></li>
  <li><a href="SAHAY_TANVI_resume2017.pdf" target="_blank">Resume</a></li>
</ul>

<p style="width:800px;margin-left:140px;margin-top:100px;font-size:22px;" align="justify">GuiTones-I: An Audio-Visual Database of Monophonic
Guitar Tones</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>IEEE Citation: </strong>A. Aggarwal, R. Kumar, T. Sahay and M. Chandra, "GuiTones-I: An audio-visual database of monophonic guitar tones," 2016 IEEE Region 10 Conference (TENCON), Singapore, 2016, pp. 497-500.</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>URL: <a href="http://ieeexplore.ieee.org/document/7848049/"> http://ieeexplore.ieee.org/document/7848049/</a></strong></p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"> <strong>Abstract:</strong> Automatic music transcription (AMT) is considered one of the most complex problems in music information retrieval (MIR). Many attempts of transcribing polyphonic music have been made in the past but monophonic tones, that build melodious music pieces, still remain largely untouched. The foremost approach is preparation of a database consisting of isolated and continuous monophonic sounds in order to proceed with the recognition and transcription of monophonic music pieces. In this paper one such audio-visual database of monophonic guitar tones for multi-modal signal processing has been introduced and evaluated for a test case of both online and offline recognition and transcription. The database comprises of recorded audio samples of first nine frets for all six strings and images of different ways in which the fretboard was held while playing these frets. A total of over 10,000 audio-visual samples have been recorded by 40 amateur and professional guitarists. The prepared database will be made available for free download under a CC BY-NC-SA 4.0 license and in DVDs at a nominal cost covering shipping and handling charges. </p>

<p style="width:1000px;margin-left:140px;margin-top:120px;font-size:22px;">Grid search analysis of nu-SVC for text-dependent speaker-identification</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>IEEE Citation: </strong>A. Aggarwal, T. Sahay, A. Bansal and M. Chandra, "Grid search analysis of nu-SVC for text-dependent speaker-identification," 2015 Annual IEEE India Conference (INDICON), New Delhi, 2015, pp. 1-5.</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>URL: <a href="http://ieeexplore.ieee.org/document/7443790/"> http://ieeexplore.ieee.org/document/7443790/</a></strong></p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"> <strong>Abstract:</strong> Recent research has strongly established the application of Support Vector Machines for Speaker Recognition. In this paper, we present the variations in efficiency of a model for various parameters of nu-SVC for text-dependent speaker-identification. Radial Basis Function (RBF), sigmoid and polynomial kernels have been used for classification. A statistical comparison between all the three kernels has been shown, highlighting the dependence of each on SVM parameters such as gamma, degree of polynomial and nu. For feature extraction, LPC, MFCC and a combination of both has been employed. The performance of RBF kernel was found to be better than Polynomial as well as Sigmoid Kernel for all feature extraction techniques, with best efficiency for MFCC. </p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"><strong>Presented with the "Best Paper Award"</strong></p>

<p style="width:1000px;margin-left:140px;margin-top:120px;font-size:22px;">SVM and ANN: A comparative evaluation</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>IEEE Citation: </strong>T. Sahay, A. Aggarwal, A. Bansal and M. Chandra, "SVM and ANN: A comparative evaluation," 2015 1st International Conference on Next Generation Computing Technologies (NGCT), Dehradun, 2015, pp. 960-964.</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>URL: <a href="http://ieeexplore.ieee.org/document/7375263/"> http://ieeexplore.ieee.org/document/7375263/</a></strong></p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"> <strong>Abstract:</strong> Support vector machines (SVMs) are among the most robust classifiers for the purpose of speech recognition. This paper compares one of the more contemporary methods of classification, artificial neural network (ANN) with support vector machines and draws conclusions based on a comparison of accuracy. The neural network is a pattern network for variable hidden neurons and transfer functions. C- Support vector classifier is used with three different kernels and kernel parameters. MFCC has been used as the feature extraction technique for a noiseless database of 50 independent speakers. The results were found to be best for SVM with RBF kernel in comparison to bi-quadratic polynomial and sigmoid kernels and pattern network. </p>

<p style="width:1000px;margin-left:140px;margin-top:120px;font-size:22px;">Performance evaluation of artificial neural networks for isolated Hindi digit recognition with LPC and MFCC</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>IEEE Citation: </strong>A. Aggarwal, T. Sahay and M. Chandra, "Performance evaluation of artificial neural networks for isolated Hindi digit recognition with LPC and MFCC," 2015 International Conference on Advanced Computing and Communication Systems, Coimbatore, 2015, pp. 1-6.</p>
<p style="width:950px;margin-left:180px;font-size:15px;"><strong>URL: <a href="http://ieeexplore.ieee.org/document/7324099/"> http://ieeexplore.ieee.org/document/7324099/</a></strong></p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"> <strong>Abstract:</strong> Artificial neural networks (ANN) are one of the most robust classifiers having a long standing history of application for voice recognition. In this paper, a comparative study between two different types of neural networks for isolated Hindi digit recognition has been presented. The two networks, pattern net and feed-forward net have been used for digits classification with multiple combinations of transfer functions and hidden neurons. LPC, MFCC and combinations of both have been used as feature extraction techniques for experiments. The results have been found in favor of pattern net for all the tested cases. A noiseless database of 50 independent speakers has been used for simulation. </p>
<p style="width:950px;margin-left:180px;font-size:15px;" align="justify"><strong>Presented with the "Best Paper Award"</strong></p>

</body>
</html>
